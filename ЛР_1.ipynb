{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Основные этапы работы:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Этап 0. Установка и настройка оболочки для работы с языком Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В лабораторной работе использовалсь среда разработки VS Code с расширением Juputer <u>version: 2024.2.0</u>.\n",
        "\n",
        "Загрузка необходимых библиотек для выполнения лаборатрных работ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QD0KDkdo7PRW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В лабораторной работе используется в обучении нейросети Keras и TensorFlow.\n",
        "Keras — это библиотека уровня модели, предоставляющая высокоуровневые строительные блоки для конструирования моделей глубокого обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Этап 1. Построение бинарного классификатора.\n",
        "**Целью этапа:** является создание бинарного классификатора отзывов к фильмам из наборы данных IMDB. \n",
        "\n",
        "**Формулировка задания:** классифицировать отзывы к фильмам на положительные и отрицательные отзывы, опираясь на текст отзывов.\n",
        "\n",
        "Вариант этапа 1\n",
        "\n",
        "| № | Количество слоев | Количество нейронов на слое | Функции активации скрытого слоя | Функция потерь |\n",
        "| :-: | :-: | :-: | :-: | :-: |\n",
        "| 3 | 2 | 32 | tanh-relu | Бинарная перекрестная энтропия |\n",
        "\n",
        "Пошаговая реализация поставленной цели включает:\n",
        "\n",
        "\t1. Загрузка набора данных IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL629qgf8ECV",
        "outputId": "00360fbd-a3f6-4e87-bc15-e991f38d74f5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "База данных состоит из 50000 отзывов к кинолентам в интернет-базе (Internet Movie Database). Набор разбит на 25000 обучающих и 25 000 контрольных отзывов, каждый набор на 50 % состоит из отрицательных и на 50 % из положительных отзывов. Набор данных IMDB поставляется в составе Keras. Набор готов к использованию: отзывы (последовательности слов) преобразованы в последовательности целых чисел, каждое из которых определяет позицию слова в словаре."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\t2. Разделение данных на обучающий и тестовый наборы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Аргумент _num_words=10000_ означает, что в обучающих данных будет сохранено только 10000 слов, наиболее часто встречающихся в обучающем наборе отзывов, остальные слова будут отброшены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переменные _train_data_ и _test_data_ — это списки отзывов; каждый отзыв — это список индексов слов (кодированное представление последовательности слов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переменные _train_labels_ и _test_labels_ — это списки нулей и единиц, где нули соответствуют отрицательным отзывам, а единицы — положительным.\n",
        "\n",
        "\t3. Подготовка данных для передачи в нейронную сеть\n",
        "\n",
        "Выполним прямое кодирование списков в векторы нулей и единиц. Это преобразование последовательности, например, [3, 5] в 10000-мерный вектор, все элементы которого содержат нули, кроме элементов с индексами 3 и 5, которые содержат единицы. Затем их можно передать в первый слой сети типа Dense, способный обрабатывать векторизованные данные с вещественными числами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0GQo1gHE87JR"
      },
      "outputs": [],
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))#1\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.#2\n",
        "    return results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Векторизуем обучающие и контрольные данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Es3MzYiD0H_f"
      },
      "outputs": [],
      "source": [
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на примере первого образца как выглядят теперь данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Векторизуем метки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5HWdKpYtO9o9"
      },
      "outputs": [],
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    4. В соответствии с вариантом, выполнить конструирование сети: выбрать количество скрытых слоев, количество нейронов в каждом слое, вид активационной функции на каждом слое\n",
        "\n",
        "С помощью функции _Sequential()_ мы создаём новую модель. Сеть будет состоять из 3 полносвязных слоёв Dense. Первый слой состоит из 64 нейронов, с функцией активацией _tanh_, и количеством в 10000 значений на входе сети. Второй слой тоже состоит из 64 нейронов, с функцией активацией _relu_. Последний слой состоит из одного нейрона с функцией активации _sigmoid_, на выходе получаем скалярное значение в диапозоне между 0 и 1, представляющее собой вероятность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YVCfBYuDP6hZ"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='tanh', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выведем архитектуру сети:\n",
        "\n",
        "В первом слое 640064 параметров, во втором 4160, в последнем 65 параметров. Всего в модели 644289 обучающихся параметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 644289 (2.46 MB)\n",
            "Trainable params: 644289 (2.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Входные данные представлены векторами, а метки — скалярами (единицами и нулями). С задачами этого\n",
        "вида прекрасно справляются сети, организованные как простой стек полносвязных (Dense) слоев. Аргумент, передаваемый каждому слою Dense, — это число скрытых нейронов слоя.\n",
        "Скрытый нейрон (hidden unit) - это измерение в пространстве представлений слоя. Наличие 32 скрытых нейронов означает, что весовая матрица W будет иметь форму (input_dimension, 32): скалярное произведение на W спроецирует входные данные в 16-мерное пространство представлений (затем будет произведено сложение с вектором смещений b и выполнена операция relu), каждый слой Dense с операцией активации relu реализует следующую цепочку операций с тензорами:\n",
        "\n",
        "<p style=\"text-align: center;\">output=relu(dot(W, input) + b)</p>\n",
        "\n",
        "Функция relu (rectified linear unit — блок линейной ректификации) используется для преобразования отрицательных значений в ноль. \n",
        "\n",
        "<center><img src=\"relu.jpg\"></center>\n",
        "<center>Рис. 1. Функция блока линейной ректификации</center>\n",
        "\n",
        "Сигмоидная функция рассредоточивает произвольные значения по интервалу [0,1], возвращая значения, которые можно интерпретировать как вероятность.\n",
        "<center><img src=\"sigmoid.jpg\"></center>\n",
        "<center>Рис. 2. Сигмоидная функция</center>\n",
        "\n",
        "    5. Настройка оптимизатора с выбором функции потерь и метрики качества"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Перекрестная энтропия (crossentropy) - это мера расстояния между распределениями вероятностей, или в данном случае - между фактическими данными и предсказаниями.\n",
        "\n",
        "Настраиваем модель оптимизатором rmsprop и функцией потерь mеап squared error.\n",
        "\n",
        "rmsprop - наиболее подходящий оптимизатор, популярный в использовании для большинства нейронных сетей.\n",
        "\n",
        "Среднеквадратичное распространение корня (RMSprop) - это экспоненциально затухающее среднее значение. Существенным свойством RMSprop является то, что вы не ограничены только суммой прошлых градиентов, но вы более ограничены градиентами последних временных шагов. В RMSProp мы пытаемся уменьшить вертикальное движение, используя среднее значение, потому что они суммируются приблизительно до 0, принимая среднее значение. RMSprop предоставляет среднее значение для обновления.\n",
        "\n",
        "    6. Проведение проверки решения, выделяя контрольное множество\n",
        "\n",
        "Для контроля точности выделим проверочное множество 10000 образцов из обучающего множества данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "keesYUdQSKFE"
      },
      "outputs": [],
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучим модель на 20 эпохах пакетами (batch_size) по 512 образцов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsnCf2YVSnLD",
        "outputId": "51c148bd-98a7-412f-9fe9-d723ff220a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.5177 - accuracy: 0.7342"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 2s 44ms/step - loss: 0.4919 - accuracy: 0.7550 - val_loss: 0.3343 - val_accuracy: 0.8691\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2855 - accuracy: 0.8876 - val_loss: 0.3747 - val_accuracy: 0.8391\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2237 - accuracy: 0.9132 - val_loss: 0.2772 - val_accuracy: 0.8842\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1672 - accuracy: 0.9369 - val_loss: 0.5290 - val_accuracy: 0.8187\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1452 - accuracy: 0.9442 - val_loss: 0.3305 - val_accuracy: 0.8790\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1188 - accuracy: 0.9570 - val_loss: 0.3868 - val_accuracy: 0.8601\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1004 - accuracy: 0.9637 - val_loss: 0.3516 - val_accuracy: 0.8803\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0891 - accuracy: 0.9681 - val_loss: 0.5302 - val_accuracy: 0.8538\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 0.4206 - val_accuracy: 0.8767\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 0.4328 - val_accuracy: 0.8745\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 0.4585 - val_accuracy: 0.8706\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.4906 - val_accuracy: 0.8711\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.5255 - val_accuracy: 0.8713\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.5171 - val_accuracy: 0.8694\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9990 - val_loss: 0.6006 - val_accuracy: 0.8705\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 0.6213 - val_accuracy: 0.8697\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 1.1546 - val_accuracy: 0.8249\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.6834 - val_accuracy: 0.8647\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.6554 - val_accuracy: 0.8673\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.7241 - val_accuracy: 0.8670\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model.fit() возвращает объект History. Этот объект имеет поле history — словарь с данными обо всем происходившем в процессе обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    7. Вывод графиков функции потерь и точности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "oAW-frYnYpFd",
        "outputId": "6cdbc963-f77f-4961-9c49-8ce670686e31"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.clf()\n",
        "plt.plot(epochs, loss_values, 'r', label='Потери на этапе обучения')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Потери на этапе проверки')\n",
        "plt.title('Потери на этапах обучения и проверки')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Потери')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.1.3.png\"></center>\n",
        "<center>Рис. 3. Потери на этапах обучения и проверки</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ubfikbvOevii",
        "outputId": "7b2b08c6-a643-44f0-a5fa-ff35f3a3ac91"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "plt.plot(epochs, acc, 'r', label='Точность на этапе обучения')\n",
        "plt.plot(epochs, val_acc, 'b', label='Точность на этапе проверки')\n",
        "plt.title('Точность на этапах обучения и проверки')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Точность')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.1.2.png\"></center>\n",
        "<center>Рис. 4. Точность на этапах обучения и проверки</center>\n",
        "\n",
        "Посмотрим какой точности достигнет наша модель обученная на 20 эпохах:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.7744 - accuracy: 0.8560\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По итогам обучения с 20 эпохами точность достигла 85,47%.\n",
        "\n",
        "На этапе обучения потери снижаются с каждой эпохой, а точность растет. Это ожидаемое поведение от оптимизации градиентным спуском: величина, которую необходимо минимизировать, становиться все меньше с каждой итерацией на обучающих данных. \n",
        "Однако потери и точность на этапе проверки достигает пика в третью эпоху. Далее происходит переобучение: после третьей эпохи произошла чрезмерная оптимизация на обучающих данных, и в результате получилось представление, характерное для обучающих данных, не обобщающее данные за пределами обучающего набора.\n",
        "\n",
        "В данном случае для предотвращения переобучения можно прекратить обучение после третьей эпохи.\n",
        "\n",
        "Скомпилируем заново модель, ограничимся тремя эпохами и проверим точность на контрольных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4IHqQzbcJNq",
        "outputId": "4819dc72-8c59-4620-fa94-8aae2337b188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 0.4351 - accuracy: 0.7991\n",
            "Epoch 2/3\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 0.2544 - accuracy: 0.8985\n",
            "Epoch 3/3\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 0.2032 - accuracy: 0.9207\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2652b3db340>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(64, activation='tanh'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgWY1wUTfjro",
        "outputId": "f865f583-8094-4735-ae75-0d19642fc0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.2912 - accuracy: 0.8806\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.29117682576179504, 0.8806399703025818]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_end = model.evaluate(x_test, y_test)\n",
        "results_end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модель обученная в течении трёх эпох показала точность в 88,06% при потерях 0.29.\n",
        "\n",
        "Посмотрим сколько мы выигрываем при обучении модели на двадцати эпохах и модели обученной на трех эпохах:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4832030236721039\n",
            "0.024599969387054443\n"
          ]
        }
      ],
      "source": [
        "print(results_end[0] - results[0])\n",
        "print(results_end[1] - results[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мы получаем не только выигрыш по времени, но и улучшаем точность на 2,46% и потери стали меньше на 0.48."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    8. Использование обученной сети для предсказания на новых данных\n",
        "\n",
        "Попробуем предсказать вероятность того, что отзывы будут положительными, с помощью метода predict:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgmUncP8w5Rw",
        "outputId": "f5034f71-c797-4763-827b-51d32036f8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.12984616],\n",
              "       [0.9984404 ],\n",
              "       [0.29253614],\n",
              "       ...,\n",
              "       [0.05470785],\n",
              "       [0.03435762],\n",
              "       [0.47761816]], dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Рузультат показывает, что сеть уверена в одних образцах (99% или 3%), но в других не так точно (47,8%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQw9ERxcwSV7"
      },
      "source": [
        "### Этап 2. Построение многоклассого классификатора.\n",
        "**Целью этапа:** является создание многоклассового классификатора новостных лент из набора данных Reuters. \n",
        "\n",
        "**Формулировка задания:** создать сеть для классификации новостных лент агентства Reuters на 46 взаимоисключающих тем. \n",
        "\n",
        "Вариант этапа 2\n",
        "\n",
        "| № | Количество слоев | Количество нейронов на слое | Функции активации скрытого слоя | Функция потерь |\n",
        "| :-: | :-: | :-: | :-: | :-: |\n",
        "| 3 | 2 | 4-32 | tanh-relu | многокатегориальная перекрестная энтропия |\n",
        "\n",
        "Пошаговая реализация поставленной цели включает:\n",
        "\n",
        "\t1. Загрузка набора данных Reuters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jV_SRIf5wN35"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import reuters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По сравнению с предыдущем этапом лабораторной работы классов больше двух, значит эта задача относится к категории задач многоклассовой классификации; и, поскольку каждый экземпляр данных должен быть отнесен только к одному классу, эта задача является примером однозначной многоклассовой классификации. \n",
        "\n",
        "Reuters - простой набор данных, широко используемых для классификации текста. Существует 46 разных тем; некоторые темы более широко представлены, некоторые менее, но для каждой из них в обучающем наборе имеется не менее 10 примеров.\n",
        "\n",
        "\t2. Разделение данных на обучающий и тестовый наборы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4xjMO3QwM3h",
        "outputId": "ea7978e3-17e9-4994-ac10-2f97e4ca60fe"
      },
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Аргумент _num_words=10000_ по аналогии с предыдущем этапом означает, что в обучающих данных будет сохранено только 10000 слов, остальные слова будут отброшены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
              "       list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),\n",
              "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
              "       ...,\n",
              "       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),\n",
              "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
              "       list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переменные _train_data_ и _test_data_ — это списки новостных лент, каждая новость — это список индексов слов (кодированное представление последовательности слов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3,  4,  3, ..., 25,  3, 25], dtype=int64)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переменные _train_labels_ и _test_labels_ — это списки меток определяющий класс принадлежности новостных лент от 0 до 45.\n",
        "\n",
        "\t3. Подготовка данных для передачи в нейронную сеть\n",
        "\n",
        "Декодируем первую новость в списке тренировочных данных и выведем её метку:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZvVHkZiyLJY",
        "outputId": "04ca9b00-ac2e-487a-cf9d-cd2637bd7da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ],
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "\n",
        "print(decoded_newswire)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В decoded_newswire мы сместили индексы на 3, так как они зарезервировали их на отступ, начало последовательности, неизвестно.\n",
        "\n",
        "Используем функцию _vectorize_sequences_, которая была написана на предыдущем этапе и выполним прямое кодирование списков в векторы из нулей и единиц:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr9aVSbfRGCZ",
        "outputId": "ab6fa921-2263-4db2-ea95-caeb894e19cf"
      },
      "outputs": [],
      "source": [
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для меток используем прямое кодирование (one-hot encoding). Прямое кодирование широко используется для форматирования категорий и также называется кодированием категорий (categorical encoding):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4m7PQsbRFqb",
        "outputId": "140f197f-ae6e-4556-905a-8dfcd5aa586a"
      },
      "outputs": [],
      "source": [
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    4. В соответствии с вариантом, выполнить конструирование сети: выбрать количество скрытых слоев, количество нейронов в каждом слое, вид активационной функции на каждом слое\n",
        "\n",
        "С помощью функции _Sequential()_ мы создаём новую модель. Сеть будет состоять из 3 полносвязных слоёв Dense. Первый слой состоит из 4 нейронов, с функцией активацией _tanh_, и количеством в 10000 значений на входе сети. Второй слой тоже состоит из 32 нейронов, с функцией активацией _relu_. Последний слой состоит из 46 нейронов с функцией активации _softmax_, возвращающий массив с 10 оценками вероятностей (в сумме дающий 1), каждая оценка определяет вероятность принадлежности к одному из 46 классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "OEpBtnL1b95d"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(4, activation='tanh', input_shape=(10000,)),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(46, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В отличие от предыдущей сети, эта завершается слоем Dense с размером 46. Это означает, что для каждого входного образца сеть будет выводить 46-мерный вектор. Каждый элемент этого вектора (каждое измерение) представляет собой отдельный выходной класс.\n",
        "\n",
        "Последний слой использует функцию активации softmax. Означает, что сеть будет выводить распределение вероятностей по 46 разным классам - для каждого образца на входе сеть будет возвращать 46-мерный вектор, где output[i] вероятность принадлежности образца классу і. Сумма 46 элементов всегда будет равна 1.\n",
        "\n",
        "Выведем архитектуру сети:\n",
        "\n",
        "В первом слое 40004 параметров, во втором 160, в последнем 1518 параметров. Всего в модели 41682 обучающихся параметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 4)                 40004     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 32)                160       \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 46)                1518      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41682 (162.82 KB)\n",
            "Trainable params: 41682 (162.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5. Настройка оптимизатора с выбором функции потерь и метрики качества\n",
        "    \n",
        "В данном случае используем функцию потерь categorical_crossentropy. Она определяет расстояние между распределениями вероятностей. В данном случае между распределением вероятности на выходе сети и истинным распределением меток. Минимизируя расстояние между этими двумя распределениями, мы учим сеть выводить результат, максимально близкий к истинным меткам.\n",
        "Оптимизатор поставим такой же как и на прошлом этапе.\n",
        "\n",
        "Скомпелируем модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "11Hzry4VfUFW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    6. Проведение проверки решения, выделяя контрольное множество\n",
        "\n",
        "Для контроля точности модели создадим проверочный набор (x_val, y_val), выбрав 1000 образцов из набора обучающих данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzITlypOiauH",
        "outputId": "5abb84d8-bb54-41d7-febf-233a460b7110"
      },
      "outputs": [],
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучим модель на 30 эпохах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAVEklOJjjoq",
        "outputId": "b0d7b373-f366-44d0-9ba2-b23cf188ecff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 20ms/step - loss: 3.6735 - accuracy: 0.2746 - val_loss: 3.4650 - val_accuracy: 0.3630\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.3245 - accuracy: 0.3926 - val_loss: 3.1478 - val_accuracy: 0.4370\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.0183 - accuracy: 0.4417 - val_loss: 2.8548 - val_accuracy: 0.4170\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.7292 - accuracy: 0.4073 - val_loss: 2.5745 - val_accuracy: 0.4110\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.4590 - accuracy: 0.4110 - val_loss: 2.3228 - val_accuracy: 0.4330\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.2240 - accuracy: 0.4553 - val_loss: 2.1133 - val_accuracy: 0.4990\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.0274 - accuracy: 0.5362 - val_loss: 1.9413 - val_accuracy: 0.5650\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.8651 - accuracy: 0.5975 - val_loss: 1.8050 - val_accuracy: 0.5990\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.7317 - accuracy: 0.6258 - val_loss: 1.6938 - val_accuracy: 0.6090\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6191 - accuracy: 0.6354 - val_loss: 1.6022 - val_accuracy: 0.6190\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5245 - accuracy: 0.6404 - val_loss: 1.5295 - val_accuracy: 0.6240\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4453 - accuracy: 0.6437 - val_loss: 1.4707 - val_accuracy: 0.6280\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3764 - accuracy: 0.6471 - val_loss: 1.4229 - val_accuracy: 0.6260\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3155 - accuracy: 0.6510 - val_loss: 1.3828 - val_accuracy: 0.6300\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2609 - accuracy: 0.6585 - val_loss: 1.3479 - val_accuracy: 0.6350\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2105 - accuracy: 0.6683 - val_loss: 1.3204 - val_accuracy: 0.6350\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1635 - accuracy: 0.6813 - val_loss: 1.2940 - val_accuracy: 0.6440\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1196 - accuracy: 0.6968 - val_loss: 1.2693 - val_accuracy: 0.6570\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0780 - accuracy: 0.7206 - val_loss: 1.2550 - val_accuracy: 0.6660\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0386 - accuracy: 0.7413 - val_loss: 1.2340 - val_accuracy: 0.6830\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0004 - accuracy: 0.7603 - val_loss: 1.2170 - val_accuracy: 0.6910\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9649 - accuracy: 0.7739 - val_loss: 1.2035 - val_accuracy: 0.6960\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9311 - accuracy: 0.7859 - val_loss: 1.1890 - val_accuracy: 0.7000\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8994 - accuracy: 0.7965 - val_loss: 1.1830 - val_accuracy: 0.7070\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8690 - accuracy: 0.8038 - val_loss: 1.1753 - val_accuracy: 0.7170\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8408 - accuracy: 0.8106 - val_loss: 1.1666 - val_accuracy: 0.7170\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8135 - accuracy: 0.8142 - val_loss: 1.1630 - val_accuracy: 0.7110\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7884 - accuracy: 0.8187 - val_loss: 1.1576 - val_accuracy: 0.7120\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7639 - accuracy: 0.8216 - val_loss: 1.1591 - val_accuracy: 0.7120\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7409 - accuracy: 0.8252 - val_loss: 1.1590 - val_accuracy: 0.7150\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим какой точности достигнет наша модель обученная на 30 эпохах:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcJYf-9Qk_k_",
        "outputId": "053a8e05-c8e6-43d1-e8cb-478888b0c0a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 890us/step - loss: 1.2485 - accuracy: 0.7012\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.2484803199768066, 0.7012466788291931]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модель обученная в течении тридцати эпох показала точность в 70,12% при потерях 1.25.\n",
        "\n",
        "    7. Вывод графиков функции потерь и точности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "D272P9W9lAO9",
        "outputId": "040fb181-7215-4f83-ef21-ee82128490b8"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'r', label='Потери на этапе обучения')\n",
        "plt.plot(epochs, val_loss, 'b', label='Потери на этапе проверки')\n",
        "plt.title('Потери на этапах обучения и проверки')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Потери')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.2.11.png\"></center>\n",
        "<center>Рис. 5. Потери на этапах обучения и проверки</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "lVAACER5lMfP",
        "outputId": "46d627ca-d0c3-412a-b9fc-3929cda668a0"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'r', label='Точность на этапе обучения')\n",
        "plt.plot(epochs, val_acc, 'b', label='Точность на этапе проверки')\n",
        "plt.title('Точность на этапах обучения и проверки')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Точность')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.2.12.png\"></center>\n",
        "<center>Рис. 6. Точность на этапах обучения и проверки</center>\n",
        "\n",
        "Как можно увидеть точность на валидационном наборе данных увеличивается, и ошибка уменьшается на протяжении 30 эпохах, поэтому попробуем увеличить количество эпох.\n",
        "\n",
        "Скомпелируем модель заново и обучим её на 50 эпохах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3NeKpjcEnEbQ"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(4, activation='tanh', input_shape=(10000,)),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(46, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v60g5lCtqTzu",
        "outputId": "4e961a3d-74d0-4b3a-e842-dfade1d4350d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "11/16 [===================>..........] - ETA: 0s - loss: 3.7091 - accuracy: 0.1042"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 17ms/step - loss: 3.6614 - accuracy: 0.1847 - val_loss: 3.4947 - val_accuracy: 0.4370\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.3543 - accuracy: 0.4921 - val_loss: 3.2079 - val_accuracy: 0.5200\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.0650 - accuracy: 0.5180 - val_loss: 2.9297 - val_accuracy: 0.5300\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.7854 - accuracy: 0.5318 - val_loss: 2.6628 - val_accuracy: 0.5410\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.5238 - accuracy: 0.5380 - val_loss: 2.4190 - val_accuracy: 0.5410\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.2930 - accuracy: 0.5361 - val_loss: 2.2130 - val_accuracy: 0.5460\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.1048 - accuracy: 0.5408 - val_loss: 2.0497 - val_accuracy: 0.5480\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.9592 - accuracy: 0.5446 - val_loss: 1.9250 - val_accuracy: 0.5450\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.8461 - accuracy: 0.5492 - val_loss: 1.8270 - val_accuracy: 0.5540\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.7488 - accuracy: 0.5672 - val_loss: 1.7353 - val_accuracy: 0.5670\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6462 - accuracy: 0.5948 - val_loss: 1.6388 - val_accuracy: 0.5970\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5568 - accuracy: 0.6059 - val_loss: 1.5784 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4880 - accuracy: 0.6128 - val_loss: 1.5297 - val_accuracy: 0.5990\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4275 - accuracy: 0.6165 - val_loss: 1.4908 - val_accuracy: 0.6070\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3721 - accuracy: 0.6242 - val_loss: 1.4564 - val_accuracy: 0.6230\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3187 - accuracy: 0.6421 - val_loss: 1.4255 - val_accuracy: 0.6310\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2668 - accuracy: 0.6630 - val_loss: 1.3970 - val_accuracy: 0.6410\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2171 - accuracy: 0.6884 - val_loss: 1.3706 - val_accuracy: 0.6560\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1690 - accuracy: 0.7068 - val_loss: 1.3433 - val_accuracy: 0.6670\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1234 - accuracy: 0.7185 - val_loss: 1.3219 - val_accuracy: 0.6730\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0798 - accuracy: 0.7285 - val_loss: 1.2979 - val_accuracy: 0.6800\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0384 - accuracy: 0.7404 - val_loss: 1.2816 - val_accuracy: 0.6840\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9993 - accuracy: 0.7553 - val_loss: 1.2667 - val_accuracy: 0.6880\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9621 - accuracy: 0.7656 - val_loss: 1.2484 - val_accuracy: 0.7010\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9272 - accuracy: 0.7751 - val_loss: 1.2401 - val_accuracy: 0.7040\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8934 - accuracy: 0.7843 - val_loss: 1.2275 - val_accuracy: 0.7120\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8618 - accuracy: 0.7899 - val_loss: 1.2216 - val_accuracy: 0.7100\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8316 - accuracy: 0.7957 - val_loss: 1.2161 - val_accuracy: 0.7160\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8031 - accuracy: 0.8007 - val_loss: 1.2126 - val_accuracy: 0.7140\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7763 - accuracy: 0.8086 - val_loss: 1.2116 - val_accuracy: 0.7140\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7509 - accuracy: 0.8133 - val_loss: 1.2111 - val_accuracy: 0.7170\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.7268 - accuracy: 0.8191 - val_loss: 1.2063 - val_accuracy: 0.7230\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.7037 - accuracy: 0.8276 - val_loss: 1.2083 - val_accuracy: 0.7220\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6816 - accuracy: 0.8312 - val_loss: 1.2178 - val_accuracy: 0.7200\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.8410 - val_loss: 1.2155 - val_accuracy: 0.7250\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.8468 - val_loss: 1.2313 - val_accuracy: 0.7260\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.8513 - val_loss: 1.2248 - val_accuracy: 0.7240\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.8554 - val_loss: 1.2329 - val_accuracy: 0.7260\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.8597 - val_loss: 1.2460 - val_accuracy: 0.7260\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.8621 - val_loss: 1.2495 - val_accuracy: 0.7320\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5558 - accuracy: 0.8677 - val_loss: 1.2484 - val_accuracy: 0.7310\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5406 - accuracy: 0.8680 - val_loss: 1.2625 - val_accuracy: 0.7320\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8727 - val_loss: 1.2644 - val_accuracy: 0.7360\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8763 - val_loss: 1.2882 - val_accuracy: 0.7330\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8782 - val_loss: 1.2839 - val_accuracy: 0.7340\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.8791 - val_loss: 1.2903 - val_accuracy: 0.7340\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.8819 - val_loss: 1.3168 - val_accuracy: 0.7320\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.8830 - val_loss: 1.3153 - val_accuracy: 0.7330\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.8850 - val_loss: 1.3230 - val_accuracy: 0.7350\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.8889 - val_loss: 1.3396 - val_accuracy: 0.7340\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 1ms/step - loss: 1.4151 - accuracy: 0.7191\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4150570631027222, 0.7190561294555664]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модель обученная в течении тридцати эпох показала точность в 71,91% при потерях 1.41.\n",
        "\n",
        "Можно заметить, что лучшая точность наступает на 43 эпохе, после просходит переобучение. Скомпелируем модель заново и обучим её на 43 эпохах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/43\n",
            "11/16 [===================>..........] - ETA: 0s - loss: 3.6770 - accuracy: 0.0707"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 16ms/step - loss: 3.6143 - accuracy: 0.0941 - val_loss: 3.4009 - val_accuracy: 0.1220\n",
            "Epoch 2/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.2419 - accuracy: 0.3316 - val_loss: 3.0716 - val_accuracy: 0.4570\n",
            "Epoch 3/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.9248 - accuracy: 0.4558 - val_loss: 2.7703 - val_accuracy: 0.4270\n",
            "Epoch 4/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.6374 - accuracy: 0.4213 - val_loss: 2.5034 - val_accuracy: 0.4140\n",
            "Epoch 5/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.3953 - accuracy: 0.4084 - val_loss: 2.2903 - val_accuracy: 0.4030\n",
            "Epoch 6/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.2045 - accuracy: 0.4153 - val_loss: 2.1206 - val_accuracy: 0.4130\n",
            "Epoch 7/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.0465 - accuracy: 0.4459 - val_loss: 1.9790 - val_accuracy: 0.4700\n",
            "Epoch 8/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.9061 - accuracy: 0.5167 - val_loss: 1.8517 - val_accuracy: 0.5290\n",
            "Epoch 9/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.7769 - accuracy: 0.5700 - val_loss: 1.7351 - val_accuracy: 0.5770\n",
            "Epoch 10/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6602 - accuracy: 0.5941 - val_loss: 1.6363 - val_accuracy: 0.5980\n",
            "Epoch 11/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.5610 - accuracy: 0.6080 - val_loss: 1.5564 - val_accuracy: 0.6020\n",
            "Epoch 12/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4758 - accuracy: 0.6194 - val_loss: 1.4901 - val_accuracy: 0.6210\n",
            "Epoch 13/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4014 - accuracy: 0.6451 - val_loss: 1.4362 - val_accuracy: 0.6320\n",
            "Epoch 14/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.6637 - val_loss: 1.3887 - val_accuracy: 0.6510\n",
            "Epoch 15/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2759 - accuracy: 0.6830 - val_loss: 1.3505 - val_accuracy: 0.6550\n",
            "Epoch 16/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2241 - accuracy: 0.6907 - val_loss: 1.3180 - val_accuracy: 0.6670\n",
            "Epoch 17/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1770 - accuracy: 0.6979 - val_loss: 1.2881 - val_accuracy: 0.6690\n",
            "Epoch 18/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1356 - accuracy: 0.7056 - val_loss: 1.2676 - val_accuracy: 0.6680\n",
            "Epoch 19/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0981 - accuracy: 0.7108 - val_loss: 1.2512 - val_accuracy: 0.6750\n",
            "Epoch 20/43\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0629 - accuracy: 0.7170 - val_loss: 1.2369 - val_accuracy: 0.6840\n",
            "Epoch 21/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0293 - accuracy: 0.7274 - val_loss: 1.2234 - val_accuracy: 0.6880\n",
            "Epoch 22/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9978 - accuracy: 0.7397 - val_loss: 1.2116 - val_accuracy: 0.6920\n",
            "Epoch 23/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9678 - accuracy: 0.7511 - val_loss: 1.1993 - val_accuracy: 0.7010\n",
            "Epoch 24/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9385 - accuracy: 0.7685 - val_loss: 1.1884 - val_accuracy: 0.7150\n",
            "Epoch 25/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.9094 - accuracy: 0.7794 - val_loss: 1.1798 - val_accuracy: 0.7160\n",
            "Epoch 26/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8824 - accuracy: 0.7876 - val_loss: 1.1711 - val_accuracy: 0.7240\n",
            "Epoch 27/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8557 - accuracy: 0.8002 - val_loss: 1.1692 - val_accuracy: 0.7220\n",
            "Epoch 28/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8302 - accuracy: 0.8077 - val_loss: 1.1635 - val_accuracy: 0.7220\n",
            "Epoch 29/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8054 - accuracy: 0.8121 - val_loss: 1.1564 - val_accuracy: 0.7260\n",
            "Epoch 30/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.7822 - accuracy: 0.8157 - val_loss: 1.1532 - val_accuracy: 0.7300\n",
            "Epoch 31/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7589 - accuracy: 0.8231 - val_loss: 1.1554 - val_accuracy: 0.7250\n",
            "Epoch 32/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7367 - accuracy: 0.8259 - val_loss: 1.1479 - val_accuracy: 0.7250\n",
            "Epoch 33/43\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7144 - accuracy: 0.8319 - val_loss: 1.1494 - val_accuracy: 0.7290\n",
            "Epoch 34/43\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6946 - accuracy: 0.8376 - val_loss: 1.1468 - val_accuracy: 0.7260\n",
            "Epoch 35/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6738 - accuracy: 0.8431 - val_loss: 1.1516 - val_accuracy: 0.7250\n",
            "Epoch 36/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6541 - accuracy: 0.8477 - val_loss: 1.1563 - val_accuracy: 0.7240\n",
            "Epoch 37/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6358 - accuracy: 0.8508 - val_loss: 1.1536 - val_accuracy: 0.7240\n",
            "Epoch 38/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6180 - accuracy: 0.8574 - val_loss: 1.1598 - val_accuracy: 0.7250\n",
            "Epoch 39/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.8608 - val_loss: 1.1705 - val_accuracy: 0.7250\n",
            "Epoch 40/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5846 - accuracy: 0.8667 - val_loss: 1.1702 - val_accuracy: 0.7310\n",
            "Epoch 41/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.8680 - val_loss: 1.1737 - val_accuracy: 0.7290\n",
            "Epoch 42/43\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5516 - accuracy: 0.8703 - val_loss: 1.1707 - val_accuracy: 0.7290\n",
            "Epoch 43/43\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.8738 - val_loss: 1.1793 - val_accuracy: 0.7300\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(4, activation='tanh', input_shape=(10000,)),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(46, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=43,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 817us/step - loss: 1.2998 - accuracy: 0.7061\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(x_test,one_hot_test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модель показала точность в 71%. Такая низкая точность обусловлена скорее всего малым количеством нейронов модели\n",
        "\n",
        "    8. Использование обученной сети для предсказания на новых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 848us/step\n",
            "[[1.2209652e-07 1.9807216e-04 3.1894984e-04 ... 2.5865191e-07\n",
            "  1.2041477e-06 1.6102700e-07]\n",
            " [1.7734680e-01 4.0573901e-03 4.3901903e-04 ... 1.1148362e-03\n",
            "  8.2914706e-04 1.3830791e-03]\n",
            " [2.1863871e-03 4.1649085e-02 2.4244498e-01 ... 7.8543660e-04\n",
            "  5.3814379e-03 9.6492312e-04]\n",
            " ...\n",
            " [7.5594414e-07 6.4406160e-04 1.7554855e-03 ... 1.4080886e-06\n",
            "  8.4369512e-06 8.0663460e-07]\n",
            " [4.0884866e-04 2.0724341e-02 4.0543254e-02 ... 4.2099136e-04\n",
            "  4.8568300e-03 2.7555783e-04]\n",
            " [4.5317758e-04 8.7876379e-01 4.9817539e-03 ... 1.1842228e-05\n",
            "  1.7861741e-04 2.7488170e-05]]\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "# Each entry in predictions is a vector of length 46\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Каждый элемент в predictions - это вектор с длиной 46. Сумма коэффициентов этого вектора равна 1. Предсказание для каждого класса - это вероятность для каждого из 46 элементов и в сумме составляет 1.\n",
        "Наибольший элемент, элемент с наибольшей вероятностью, — это предсказанный класс."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYm7kUvBwLyf"
      },
      "source": [
        "### Этап 3. Построение прогноза на основе регрессионной модели\n",
        "**Целью этапа:** является создание нейронной сети, дающей прогноз цен на дома из набора данных Boston Housing.\n",
        "\n",
        "**Формулировка задания:** построить регрессионную модель для предсказания медианной цены на дома в пригороде Бостона.\n",
        "\n",
        "Вариант этапа 3\n",
        "\n",
        "| № | Количество слоев | Количество нейронов на слое | Функции активации скрытого слоя | Функция потерь |\n",
        "| :-: | :-: | :-: | :-: | :-: |\n",
        "| 3 | 2 | 64-64 | tanh-tanh | среднеквадратическая погрешность |\n",
        "\n",
        "Пошаговая реализация поставленной цели включает:\n",
        "\n",
        "\t1. Загрузка набора данных Boston Housing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dD3hpzYDxfNO"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import boston_housing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В этом этапе мы попытаемся предсказать медианную цену на дома в пригороде Бостона в середине 1970 года. Для этого используем регрессионную модель.\n",
        "Основное отличие скалярной регрессии от двух предыдущих этапов, заключается в предсказании не дискретной метки, а значения на непрерывной числовой прямой: например, температуры воздуха на завтра по имеющимся метеорологическим данным или предсказание времени завершения программного проекта по его спецификациям.\n",
        "\n",
        "Для предсказания воспользуемся данными, как уровень преступности, ставка местного имущественного налога и т. д. Используемый набор данных, имеет интересное отличие от двух предыдущих этапов. Он содержит относительно немного образцов данных: всего 506, разбитых на 404 обучающих и 102 контрольных образца. И каждый признак во входных данных (например, уровень преступности) имеет свой масштаб. Например, некоторые признаки являются пропорциями и имеют значения между 0 и 1, другие - между 1 и 12 и т.д.\n",
        "\n",
        "\t2. Разделение данных на обучающий и тестовый наборы\n",
        "\n",
        "В наборе данных содержится 404 обучающих и 102 контрольных образца, каждый с 13 числовыми признаками."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ma3OnQnswIVD"
      },
      "outputs": [],
      "source": [
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вид тестового набора данных представляет собой медианные значения цен на дома, занимаемые собственниками, в тысячах долларов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQcP3h_u0dmi",
        "outputId": "e75dd79d-0a62-42ba-f960-751021989cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\t3. Подготовка данных для передачи в нейронную сеть\n",
        "\n",
        "Можно увидеть, что значения имеют самые разные диапазоны, сеть, конечно может справится, однако это усложнит обучение, обычно в таких случаях принимают нормализацию. Суть нормализации состоит в том что для каждого признака во входных данных (столбца в матрице входных данных) из каждого значения вычитается среднее по этому признаку, и разность делится на стандартное отклонение, в результате признак центрируется по нулевому значению и имеет стандартное отклонение, равное единице."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AtKJXMvCgaBb"
      },
      "outputs": [],
      "source": [
        "mean=train_data.mean(axis=0)\n",
        "train_data-=mean\n",
        "std=train_data.std(axis=0)\n",
        "train_data/=std\n",
        "test_data-=mean\n",
        "test_data/=std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    4. В соответствии с вариантом, выполнить конструирование сети: выбрать количество скрытых слоев, количество нейронов в каждом слое, вид активационной функции на каждом слое\n",
        "    \n",
        "    5. Настройка оптимизатора с выбором функции потерь и метрики качества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сеть состоит из двух скрытых слоев с функциями активации tanh и по 64 нейрона и заканчивается одномерным слоем (линейным слоем), не имеющим функции активации, т.к. функция активации могла бы ограничить диапозон выходных значений. Это конфигурация для скалярной регрессии, целью которой является предсказание одного значения на непрерывной числовой прямой. В данном случае, с линейным последним слоем, сеть способна предсказывать значения из любого диапазона.\n",
        "\n",
        "Скомпелировали модель с помощью функции _compile_(). Параметры были выбраны следующие: оптимизатор - rmsprop, функция потерь: mse (mean squared error, в перводе, среднеквадратичная ошибка), вычисляющей квадрат разности между предсказанными и целевыми значениями. Для мониторинга этапов обучения используем mae (mean absolute error) - средняя абсолютная ошибка. Это абсолютное значение разности предсказанными и целевыми значениями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FPObkR1NgZtH"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(64,activation='tanh',input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64,activation='tanh'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выведем архитектуру сети:\n",
        "\n",
        "В первом слое 896 параметров, во втором 4160, в последнем 65 параметров. Всего в модели 5121 обучающихся параметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5121 (20.00 KB)\n",
            "Trainable params: 5121 (20.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    6. Проведение проверки решения, используя метод перекрестной проверки по К блокам. Выбрать количество блоков К как количество слоев плюс один\n",
        "    \n",
        "Набор данных содержит малое количество экземпляров, соответственно проверочных данных всего 102, это очень мало. Следовательно мы не можем объективно оценить этапы обучения модели, потому как оценки при проверке могут сильно варивораться в зависимости от того, какие данные попадут в проверочный и обучающий наборы.\n",
        "\n",
        "Для решения этой проблемы используем перекрестную проверку по K блокам (K-fold cross-validation).\n",
        "Суть проверки по К блокам заключается в разделении доступных данных на К блоков, создании К идентичных моделей и обучении каждой на К-1 блоках с оценкой по оставшимся блокам. По полученным К оценкам вычисляется среднее значение, которое принимается как оценка модели. На рисунке 7 изображен пример разбиения данных на 3 блока.\n",
        "\n",
        "<center><img src=\"1.3.1.png\"></center>\n",
        "<center>Рис. 7. Перекрестная проверка по трем блокам</center>\n",
        "\n",
        "Реализация перекрестной проверки по K блокам написана в функции check():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YMv1Y_GX0QOV"
      },
      "outputs": [],
      "source": [
        "def check():\n",
        "    val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples] # Подготовка проверочных данных из блока с номером k\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate( # Подготовка обучающих данных из остальных блоков\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    return val_data, val_targets, partial_train_data, partial_train_targets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По варианту задания количество блоков зададим _K = 3_.\n",
        "\n",
        "Обучим модель на 100 эпохах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4hk-t1A1aXr",
        "outputId": "e39dc459-4f25-4e9d-c0ca-90c770b39a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing fold #0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\svyatoslav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "Processing fold #1\n",
            "Processing fold #2\n"
          ]
        }
      ],
      "source": [
        "k=3\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores =[]\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data, val_targets, partial_train_data, partial_train_targets = check()\n",
        "    model = build_model() # Конструирование модели\n",
        "    model.fit(partial_train_data, partial_train_targets, # Обучение модели (в режиме без вывода сообщений, verbose = 0)\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0) # Оценка модели по проверочным данным\n",
        "    all_scores.append(val_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выведем среднюю ошибку трех прогонов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLFnpTJuF_DB",
        "outputId": "c46512f8-8600-4e9c-a689-ee1453f09265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.3323349952697754, 2.50785493850708, 2.8250732421875]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.5550877253214517"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(all_scores)\n",
        "np.mean(all_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Средняя оценка ошибки прогнозирования составляет 2555 долларов США.\n",
        "\n",
        "Увеличим количество эпох до 500:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n_Twwb0FGClG"
      },
      "outputs": [],
      "source": [
        "num_epochs = 500 #\n",
        "all_mae_histories =[]\n",
        "for i in range(k):\n",
        "    val_data, val_targets, partial_train_data, partial_train_targets = check()\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вычислим средние значения метрики mae для всех прогонов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lv4HL_K3DBI_"
      },
      "outputs": [],
      "source": [
        "average_mae_history=[np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJk26lskZws"
      },
      "source": [
        "    7. Вывод графиков функции потерь и точности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ChCE4aQUHaZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Эпохи\")\n",
        "plt.ylabel(\"Оценка MAE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.3.2.png\"></center>\n",
        "<center>Рис. 8.  Оценки MAE по эпохам</center>\n",
        "\n",
        "Из-за проблем с масштабированием и относительно высокой дисперсии опустим первые 60 замеров из-за проблем с масштабированием и заменим оценки экспоненциально скользящим средним по предыдущим оценкам.\n",
        "\n",
        "Формирование графика с оценками проверок за исключением первых 60 замеров реализована в функции _smooth_curve()_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points=[]\n",
        "    for point in points:\n",
        "      if smoothed_points:\n",
        "        previous=smoothed_points[-1]\n",
        "        smoothed_points.append(previous*factor+point*(1-factor))\n",
        "      else:\n",
        "        smoothed_points.append(point)\n",
        "    return smoothed_points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK7KnJ6FUIDM"
      },
      "outputs": [],
      "source": [
        "truncated_mae_history = smooth_curve(average_mae_history[60:])\n",
        "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
        "plt.xlabel(\"Эпохи\")\n",
        "plt.ylabel(\"Оценки MAE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"1.3.3.png\"></center>\n",
        "<center>Рис. 9. Оценки MAE по эпохам за исключением первых 60 замеров</center>\n",
        "\n",
        "Согласно этому графику, наилучшая оценка МАЕ достигается где-то на 150 эпохе. После этого момента начинается переобучение. Обучим модель на 150 эпох, только на всем объеме обучающих данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wl3z3a8hVMzL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 14.4584 - mae: 2.3720\n"
          ]
        }
      ],
      "source": [
        "model = build_model() # Получить новую скомпилированную модель\n",
        "model.fit(train_data, train_targets, \n",
        "          epochs=150, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Nghz18HdVOzT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3719701766967773"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_mae_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Средняя оценка ошибки прогнозирования составляет около 2372 долларов США.\n",
        "\n",
        "<p style=\"text-align: center;\">Заключение</p>\n",
        "\n",
        "1. На первом этапе мы классифицировали отзывы к фильмам на положительные и отрицательные опираясь на текст отзывов. Использовали набор данных IMDB с 50000 отзывами. Подготовили данные для передачи в сеть с помощью прямого кодирования списков, т.е. закодировали последовательности целых чисел в бинарную матрицу. Сконструировали сеть согласно варианту, состоящую из двух слоев, с 64 нейронами, функции активации скрытых слоев tanh-relu, на выходном слое Dense была использована функция sigmoid, которая на выходе дает скалярное значение в диапозоне от 0 до 1, была использована бинарная перекрестная энтропия, как функция потерь. Скомпелировали и обучили модель сначала на 20 эпохах, но появляется эффект переобучения сети после третьей эпохи, потом переобучили сеть на трех эпохах, в итоге получили модель показывающаяся точность в 88.06% при потерях в 0.29. Также предсказали вероятность пернадлежности тестовых данных.\n",
        "\n",
        "2. На втором этапе мы классифицировали новостные ленты по их темам, опираясь на их текст. Использовали набор данных Reuters c 11228 новостей. Подготовили данные для передачи в сеть с помощью прямого кодирования как в предыдущем этапе лабораторной работы. Сконструировали сеть согласно варианту, состоящую из двух слоев, на первом слое было использовано 4 нейрона, на втором слое использовано 32 нейрона, функции активации скрытых слоев tanh-relu, на выходном слое была использована функция softmax для распределения вероятностей определения класса новосных лент, на этом этапе была использована многокатегориальная перекрестная энтропия, как функция потерь, которая определяет расстояние между распределениями вероятностей. Для нахождения оптимального количество эпох обучения было выбрано сначало 30 эпох, однако результаты и графики показали, что этого было недостаточно, потом обучили на 50 эпохах, в итоге после 43 эпохи начилось переобучение модели. Обучив модель на 43 эпохах получили точность в 71%, при потерях 1.41. Такая малая точность обусловлена малым количеством нейронов на слоях модели. Также предсказали вероятность пернадлежности тестовых данных к каждому из классов новостных лент.\n",
        "\n",
        "3. В третьем этапе была решена задача регрессии, она выполняется с применением иных функций потерь, нежели классификация. В этой задаче Использовали набор данных boston_housing, с количеством 506 экземпляров. Обработали данные с помощью нормализации. Сконструировали сеть согласно варианту, состоящую из двух скрытых слоев, с функциями активации tanh и по 64 нейрона и заканчивается одномерным слоем (линейным слоем), не имеющим функции активации. Получается, сеть с линейным последним слоем, сеть способна предсказывать значения из любого диапазона. Скомпелировали модель с парматрами: оптимизатор - rmsprop, функция потерь: mse (среднеквадратичная ошибка) и метрику оценки mae (средняя абсолютная ошибка). Из-за малого количества данных boston_housing решили надежно оценить качество модели с помощью метода перекрестной проверки по K блокам. Обучили модель на 500 эпохах, однако при оценке обучения из-за проблем с масштабированием, а также ввиду относительно высокой дисперсии затруднительно увидеть общую тенденцию. Для оптимизации были опущены первые 60 замеров, которые имеют другой масштаб, отличный от масштаба остальной кривой, а также каждая оценка была заменена экспоненциальным скользящим средним по предыдущим оценкам. В результате переобучили модель на 150 эпох, в итоге средняя оценка ошибки прогнозирования составляет около 2372 долларов США.\n",
        "\n",
        "<p style=\"text-align: center;\">Список использованной литературы</p>\n",
        "    1. Шолле Франсуа. Глубокое обучение на Python. - СПб.: Питер, 2018. - 400 с.: ил. - (Серия «Библиотека программиста»)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
